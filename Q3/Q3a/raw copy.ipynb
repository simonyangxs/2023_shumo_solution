{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af8bfa0-2cf4-46a0-9c9b-6d980f054644",
   "metadata": {},
   "source": [
    "\n",
    "## 这是对1.b任务的预处理和\n",
    "#1.a 只有有label和时间处理\n",
    "\n",
    "1. load——data\n",
    "2. 统计特征数量（清洗）、选择、分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fc1036-6924-47fc-ad99-288beea48670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import *\n",
    "import os\n",
    "import math\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9385fb6",
   "metadata": {},
   "source": [
    "## load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dbcfa63-5dc6-44de-b32a-a450f060ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "160\n",
      "158\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "#疾病史，发病和治疗\n",
    "tab1 = pd.read_excel('../../Q1/Q1a/metadata/表1-患者列表及临床信息.xlsx')\n",
    "tab1 = tab1.rename(columns={'Unnamed: 0': 'ID'})\n",
    "tab1 = tab1.rename(columns={'90天mRS': 'label'})\n",
    "del tab1['数据集划分']\n",
    "print(tab1.ID.nunique())\n",
    "\n",
    "\n",
    "#血肿总体积和水肿总体积\n",
    "tab2 = pd.read_excel('../../Q1/Q1a/metadata/表2-患者影像信息血肿及水肿的体积及位置.xlsx')\n",
    "tab2 = tab2.rename(columns={'Unnamed: 0': 'ID'})\n",
    "tab2 = tab2.iloc[:,:22+2]\n",
    "tab2 = tab2.rename(columns={'首次检查流水号': '流水号'})\n",
    "print(tab2.ID.nunique())\n",
    "\n",
    "#水肿影像\n",
    "tab3 = pd.read_excel('../../Q1/Q1a/metadata/表3-患者影像信息血肿及水肿的形状及灰度分布.xlsx',sheet_name='ED') \n",
    "del tab3['备注']\n",
    "tab3.columns = [col if '流水号' in col else 'ED_'+col   for col in tab3.columns]\n",
    "print(tab3[tab3.流水号.isin(tab2.流水号)].流水号.nunique())\n",
    "\n",
    "#血肿影像\n",
    "tab4 = pd.read_excel('../../Q1/Q1a/metadata/表3-患者影像信息血肿及水肿的形状及灰度分布.xlsx',sheet_name='Hemo') \n",
    "del tab4['备注']\n",
    "tab4.columns = [col if '流水号' in col else 'HM_'+col   for col in tab4.columns]\n",
    "print(tab4[tab4.流水号.isin(tab2.流水号)].流水号.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43251686-18df-4e2c-aebc-0392b84344a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge\n",
    "all_data = tab1.merge(tab2,how='outer')\n",
    "all_data = all_data.merge(tab3,how='left')\n",
    "all_data = all_data.merge(tab4,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0e9f7f-1ee0-479a-8ec7-92b644bcd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#发现异常：存在首次异常这个数值错误\n",
    "\n",
    "# https://www.shumo.com/forum/forum.php?mod=viewthread&tid=100012&page=1#pid240978\n",
    "# 131（3）和132（4） ，属于同一个人。直接使用3和4的来替换。 -- 使用131和132流水号根本匹配不了\n",
    "# 74号患者使用哪一个流水号：是表一记录错误，这不是它的首次，二是第二次。  ---  直接删除表1的入院首次影像检查流水号\n",
    "all_data[all_data.入院首次影像检查流水号 != all_data.流水号]\n",
    "del all_data['入院首次影像检查流水号']\n",
    "del all_data['流水号']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d9aa00",
   "metadata": {},
   "source": [
    "## 类型转换,异常值处理。归一化\n",
    "\n",
    "1. 没有空值\n",
    "2. 总量过少，异常值过少。同时outliers存在是有意义的，比如之前的MRS得分\n",
    "3. max-min归一化可以做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949fcaac-a6be-4513-9132-e266a04bc83f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_mapping = {'男': 1, '女': 0}\n",
    "all_data['性别'] = all_data['性别'].map(gender_mapping)\n",
    "all_data[['收缩压', '舒张压']] = all_data['血压'].str.split('/', expand=True)\n",
    "del all_data['血压']\n",
    "\n",
    "for i in list( all_data.columns )[1:]:\n",
    "    if(i in ['性别','高血压病史','卒中病史','糖尿病史','房颤史','冠心病史','吸烟史','饮酒史','脑室引流', '止血治疗','降颅压治疗','降压治疗','镇静、镇痛治疗','止吐护胃','营养神经']):\n",
    "        all_data[i] = all_data[i].astype('int')\n",
    "    else:\n",
    "        all_data[i] = all_data[i].astype('float')\n",
    "    \n",
    "len(list( all_data.columns ) ) #正确的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0689fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['label']\n",
    "features =list( all_data.columns )[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa08a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.loc[ all_data['ID'] != 'sub131']\n",
    "t = all_data.loc[ all_data['ID'] == 'sub003']\n",
    "t['ID'] = 'sub131'\n",
    "all_data=all_data.append(t)\n",
    "\n",
    "all_data = all_data.loc[ all_data['ID'] != 'sub132']\n",
    "t = all_data.loc[ all_data['ID'] == 'sub004']\n",
    "t['ID'] = 'sub132'\n",
    "all_data=all_data.append(t)\n",
    "all_data.sort_values(['ID'],inplace=True)\n",
    "all_data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0166c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column label missing ratio: 58\n"
     ]
    }
   ],
   "source": [
    "## trainset和全体里面的空值: 没有空值\n",
    "# 遍历每个列\n",
    "for col in all_data.columns:\n",
    "    # 计算空值\n",
    "    missing_ratio = all_data[col].isnull().sum()\n",
    "    if(missing_ratio>0):\n",
    "        print(f\"Column {col} missing ratio: {missing_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc66295b-b61b-4005-aa77-58eea8c91bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "脑出血前mRS评分\n",
      "Deleting 8 outliers in column 脑出血前mRS评分\n",
      "发病到首次影像检查时间间隔\n",
      "Deleting 6 outliers in column 发病到首次影像检查时间间隔\n",
      "HM_volume\n",
      "Deleting 3 outliers in column HM_volume\n",
      "Deleting 4 outliers in column HM_ACA_R_Ratio\n",
      "Deleting 3 outliers in column HM_PCA_R_Ratio\n",
      "Deleting 5 outliers in column HM_Pons_Medulla_R_Ratio\n",
      "Deleting 3 outliers in column HM_Cerebellum_R_Ratio\n",
      "Deleting 2 outliers in column HM_ACA_L_Ratio\n",
      "Deleting 5 outliers in column HM_PCA_L_Ratio\n",
      "HM_Pons_Medulla_L_Ratio\n",
      "Deleting 8 outliers in column HM_Pons_Medulla_L_Ratio\n",
      "Deleting 3 outliers in column HM_Cerebellum_L_Ratio\n",
      "ED_volume\n",
      "Deleting 1 outliers in column ED_volume\n",
      "ED_ACA_R_Ratio\n",
      "Deleting 5 outliers in column ED_ACA_R_Ratio\n",
      "Deleting 2 outliers in column ED_PCA_R_Ratio\n",
      "Deleting 2 outliers in column ED_Pons_Medulla_R_Ratio\n",
      "Deleting 3 outliers in column ED_Cerebellum_R_Ratio\n",
      "ED_ACA_L_Ratio\n",
      "Deleting 3 outliers in column ED_ACA_L_Ratio\n",
      "ED_PCA_L_Ratio\n",
      "Deleting 4 outliers in column ED_PCA_L_Ratio\n",
      "ED_Pons_Medulla_L_Ratio\n",
      "Deleting 3 outliers in column ED_Pons_Medulla_L_Ratio\n",
      "ED_Cerebellum_L_Ratio\n",
      "Deleting 2 outliers in column ED_Cerebellum_L_Ratio\n",
      "ED_original_shape_LeastAxisLength\n",
      "Deleting 1 outliers in column ED_original_shape_LeastAxisLength\n",
      "Deleting 1 outliers in column ED_original_shape_MajorAxisLength\n",
      "ED_original_shape_Maximum2DDiameterRow\n",
      "Deleting 1 outliers in column ED_original_shape_Maximum2DDiameterRow\n",
      "ED_original_shape_MeshVolume\n",
      "Deleting 1 outliers in column ED_original_shape_MeshVolume\n",
      "Deleting 2 outliers in column ED_original_shape_Sphericity\n",
      "ED_original_shape_SurfaceArea\n",
      "Deleting 1 outliers in column ED_original_shape_SurfaceArea\n",
      "Deleting 5 outliers in column ED_original_shape_SurfaceVolumeRatio\n",
      "ED_original_shape_VoxelVolume\n",
      "Deleting 1 outliers in column ED_original_shape_VoxelVolume\n",
      "ED_NCCT_original_firstorder_Energy\n",
      "Deleting 1 outliers in column ED_NCCT_original_firstorder_Energy\n",
      "Deleting 1 outliers in column ED_NCCT_original_firstorder_InterquartileRange\n",
      "ED_NCCT_original_firstorder_Kurtosis\n",
      "Deleting 2 outliers in column ED_NCCT_original_firstorder_Kurtosis\n",
      "ED_NCCT_original_firstorder_Maximum\n",
      "Deleting 1 outliers in column ED_NCCT_original_firstorder_Maximum\n",
      "Deleting 1 outliers in column ED_NCCT_original_firstorder_MeanAbsoluteDeviation\n",
      "Deleting 1 outliers in column ED_NCCT_original_firstorder_Range\n",
      "ED_NCCT_original_firstorder_Skewness\n",
      "Deleting 2 outliers in column ED_NCCT_original_firstorder_Skewness\n",
      "Deleting 1 outliers in column ED_NCCT_original_firstorder_Variance\n",
      "Deleting 1 outliers in column HM_original_shape_Flatness\n",
      "Deleting 2 outliers in column HM_original_shape_LeastAxisLength\n",
      "HM_original_shape_MajorAxisLength\n",
      "Deleting 2 outliers in column HM_original_shape_MajorAxisLength\n",
      "Deleting 3 outliers in column HM_original_shape_Maximum2DDiameterColumn\n",
      "HM_original_shape_Maximum2DDiameterRow\n",
      "Deleting 2 outliers in column HM_original_shape_Maximum2DDiameterRow\n",
      "Deleting 2 outliers in column HM_original_shape_Maximum2DDiameterSlice\n",
      "HM_original_shape_MeshVolume\n",
      "Deleting 3 outliers in column HM_original_shape_MeshVolume\n",
      "HM_original_shape_MinorAxisLength\n",
      "Deleting 3 outliers in column HM_original_shape_MinorAxisLength\n",
      "HM_original_shape_SurfaceArea\n",
      "Deleting 4 outliers in column HM_original_shape_SurfaceArea\n",
      "Deleting 3 outliers in column HM_original_shape_SurfaceVolumeRatio\n",
      "HM_original_shape_VoxelVolume\n",
      "Deleting 3 outliers in column HM_original_shape_VoxelVolume\n",
      "HM_NCCT_original_firstorder_Energy\n",
      "Deleting 3 outliers in column HM_NCCT_original_firstorder_Energy\n",
      "Deleting 3 outliers in column HM_NCCT_original_firstorder_Entropy\n",
      "Deleting 3 outliers in column HM_NCCT_original_firstorder_Kurtosis\n",
      "Deleting 1 outliers in column HM_NCCT_original_firstorder_Maximum\n",
      "HM_NCCT_original_firstorder_Minimum\n",
      "Deleting 2 outliers in column HM_NCCT_original_firstorder_Minimum\n",
      "Deleting 1 outliers in column HM_NCCT_original_firstorder_Range\n",
      "Deleting 2 outliers in column HM_NCCT_original_firstorder_Skewness\n",
      "Deleting 3 outliers in column HM_NCCT_original_firstorder_Uniformity\n",
      "Deleting 1 outliers in column 收缩压\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexlist= []\n",
    "## 异常值,使用统计方法衡量的异常在在合理情况\n",
    "for col in all_data.columns:\n",
    "    # 判断并删除异常值\n",
    "    if all_data[col].dtype == np.number:\n",
    "        std_dev = all_data[col].std()\n",
    "        mean_val = all_data[col].mean()\n",
    "        sigma = 3\n",
    "        outliers = all_data[all_data[col].gt(mean_val + sigma * std_dev) | all_data[col].lt(mean_val - sigma * std_dev)]\n",
    "        if( outliers.label.mean() > all_data.label.mean() ): print(col)\n",
    "        if not outliers.empty:\n",
    "            #print(outliers)\n",
    "            indexlist+=(list(outliers[col].index))\n",
    "            print(f\"Deleting {len(outliers)} outliers in column {col}\")\n",
    "len(set(indexlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253989d3-ebd4-4bf0-8cf2-8a9fd71ed613",
   "metadata": {},
   "source": [
    "### 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddbfff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 定义MinMaxScaler对象\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 对train数据集做归一化\n",
    "train_normalized =scaler.fit_transform(all_data[features]) #scaler.fit_transform(all_data[~ all_data['label'].isnull() ][features])\n",
    "\n",
    "# 对test数据集做归一化（使用前面定义的scaler）\n",
    "all_data[features] = scaler.transform(all_data[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0181ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 尝试使用pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "X_train = all_data[features ]\n",
    "# 创建PCA对象并指定要保留的主成分数量（根据需求调整）\n",
    "n_components = 10 # 选择要保留的主成分数量\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# 使用PCA对特征矩阵进行降维\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# X_pca 包含了降维后的特征矩阵\n",
    "t = pd.DataFrame(X_pca)\n",
    "t['label'] = all_data[target_column ]\n",
    "t.to_csv('./data5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d3ff321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    160.000000\n",
       "mean       0.142795\n",
       "std        0.193779\n",
       "min        0.000000\n",
       "25%        0.031579\n",
       "50%        0.073684\n",
       "75%        0.157895\n",
       "max        1.000000\n",
       "Name: 发病到首次影像检查时间间隔, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['发病到首次影像检查时间间隔'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9c6370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[features+target_column ].to_csv('./data1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc13942",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e277254",
   "metadata": {},
   "source": [
    "\n",
    "## 灰色关联度分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02374181",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_data.head(100)\n",
    "select_columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef750b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算灰度关联系数\n",
    "def grey_relation_coefficient(x, y):\n",
    "    x,y = np.array(x),np.array(y).ravel()\n",
    "    min_x = x.min()\n",
    "    max_x = x.max()\n",
    "    min_y = y.min()\n",
    "    max_y = y.max()\n",
    "    rho = 0.15  # 灰度关联系数计算时的参数，可根据需要调整\n",
    "    return np.abs((min_x - x) / (max_x - min_x) - (min_y - y) / (max_y - min_y)) / (rho + np.abs((min_x - x) / (max_x - min_x) + (min_y - y) / (max_y - min_y)))\n",
    "\n",
    "grey_relational_matrix = pd.DataFrame()\n",
    "y = (train_df[target_column].values.tolist())\n",
    "for feature in select_columns:\n",
    "    grey_relational_matrix[feature] = grey_relation_coefficient( list(train_df[feature]) ,list( y)) \n",
    "\n",
    "# 求平均灰度关联系数，用于特征排序\n",
    "average_grey_relation = grey_relational_matrix.mean(axis=1)\n",
    "average_grey_relation = average_grey_relation.sort_values(ascending=False)\n",
    "average_grey_relation.describe()\n",
    "\n",
    "# 根据灰度关联系数排序特征\n",
    "ranked_features = average_grey_relation[average_grey_relation>.35].index\n",
    "len(ranked_features)\n",
    "select_columns = list(grey_relational_matrix.iloc[:,ranked_features].columns)\n",
    "len(select_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2f7f30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    0.579040\n",
       "50    0.573479\n",
       "11    0.554614\n",
       "58    0.540017\n",
       "1     0.529613\n",
       "76    0.528488\n",
       "41    0.521811\n",
       "91    0.516366\n",
       "31    0.515880\n",
       "29    0.514529\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_grey_relation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3778a13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ED_NCCT_original_firstorder_90Percentile',\n",
       " 'ED_original_shape_Sphericity',\n",
       " '脑室引流']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "584f7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[select_columns+target_column ].to_csv('./data2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc0ccf",
   "metadata": {},
   "source": [
    "\n",
    "## 弹性网回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b947dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "X_train = (train_df[select_columns].values)\n",
    "y_train = (train_df[target_column].values)\n",
    "\n",
    "# for i in np.linspace(.1, 1, num=10) :\n",
    "#     elastic_net = ElasticNetCV(l1_ratio=[i])  # 尝试不同的l1_ratio值\n",
    "#     elastic_net.fit(X_train, y_train)\n",
    "#     optimal_l1_ratio = elastic_net.l1_ratio_\n",
    "#     print( i,len(np.where(elastic_net.coef_ != 0)[0]) )\n",
    "\n",
    "elastic_net = ElasticNetCV(l1_ratio=[.6])  # 尝试不同的l1_ratio值\n",
    "elastic_net.fit(X_train, y_train)\n",
    "optimal_l1_ratio = elastic_net.l1_ratio_\n",
    "print( .1,len(np.where(elastic_net.coef_ != 0)[0]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e07d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50bca30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ED_NCCT_original_firstorder_90Percentile</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ED_original_shape_LeastAxisLength</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ED_NCCT_original_firstorder_RobustMeanAbsolute...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ED_NCCT_original_firstorder_Median</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HM_Pons_Medulla_R_Ratio</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HM_original_shape_LeastAxisLength</td>\n",
       "      <td>0.337651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HM_original_shape_SurfaceArea</td>\n",
       "      <td>0.343855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>年龄</td>\n",
       "      <td>0.450578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HM_original_shape_Maximum2DDiameterColumn</td>\n",
       "      <td>0.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>冠心病史</td>\n",
       "      <td>0.973130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name     value\n",
       "0            ED_NCCT_original_firstorder_90Percentile  0.000000\n",
       "30                  ED_original_shape_LeastAxisLength  0.000000\n",
       "64  ED_NCCT_original_firstorder_RobustMeanAbsolute...  0.000000\n",
       "63                 ED_NCCT_original_firstorder_Median  0.000000\n",
       "33                            HM_Pons_Medulla_R_Ratio  0.000000\n",
       "..                                                ...       ...\n",
       "10                  HM_original_shape_LeastAxisLength  0.337651\n",
       "19                      HM_original_shape_SurfaceArea  0.343855\n",
       "75                                                 年龄  0.450578\n",
       "25          HM_original_shape_Maximum2DDiameterColumn  0.708995\n",
       "53                                               冠心病史  0.973130\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame()\n",
    "t['name'] = select_columns\n",
    "t['value'] = elastic_net.coef_\n",
    "t['value'] = np.abs(t['value'])\n",
    "t.sort_values(['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21ae2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = train_df[select_columns].iloc[:,(np.where(elastic_net.coef_ != 0)[0])].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fc08ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[list(select_columns)+target_column ].to_csv('./data6.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40caefe6",
   "metadata": {},
   "source": [
    "## svm递归特征消除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b66f4f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['性别',\n",
       " 'HM_original_shape_LeastAxisLength',\n",
       " 'HM_ACA_R_Ratio',\n",
       " 'HM_original_shape_Maximum2DDiameterColumn',\n",
       " 'ED_NCCT_original_firstorder_Entropy',\n",
       " 'HM_PCA_R_Ratio',\n",
       " 'ED_NCCT_original_firstorder_Uniformity',\n",
       " '冠心病史',\n",
       " 'HM_original_shape_MajorAxisLength',\n",
       " '年龄']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# 创建SVM分类器\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "X_train = (train_df[select_columns].values)\n",
    "y_train = (train_df[target_column].values)\n",
    "\n",
    "# 使用递归特征消除来选择特征\n",
    "rfe = RFE(estimator=svm, n_features_to_select=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# 获取选择的特征的索引\n",
    "selected_features_indices = np.where(rfe.support_)[0]\n",
    "selected_features = train_df[select_columns].iloc[:, selected_features_indices]\n",
    "select_columns = list(selected_features.columns)\n",
    "select_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2db90c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[select_columns+target_column ].to_csv('./data7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42c4291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.495179\n",
       "1      0.365019\n",
       "2      0.387395\n",
       "3      0.716242\n",
       "4      0.330957\n",
       "         ...   \n",
       "155    0.473792\n",
       "156    0.346794\n",
       "157    0.342428\n",
       "158    0.288904\n",
       "159    0.385834\n",
       "Name: HM_NCCT_original_firstorder_Maximum, Length: 160, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['HM_NCCT_original_firstorder_Maximum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93eef8",
   "metadata": {},
   "source": [
    "# 独立性检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df9b36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = all_data[select_columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0258f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as stats\n",
    "# import itertools\n",
    "# result=[]\n",
    "# hyperparameter_combinations = list(itertools.product(t1.columns, t1.columns))\n",
    "# for i,j in hyperparameter_combinations:\n",
    "#     if(i==j):\n",
    "#         continue\n",
    "#     group1, group2 = t1[i],t1[j]\n",
    "#     # 执行卡方独立性检验\n",
    "#     contingency_table  = pd.crosstab(t1[i],t1[j])\n",
    "#     chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "#     corr_coefficient, p_value1 = stats.pearsonr(group1, group2)\n",
    "#     result .append([i,j,  p,p_value1   ])\n",
    "# result = pd.DataFrame(result)\n",
    "# for i in range(2,4):\n",
    "#     print(result[result[i]<.01].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be0a504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import itertools\n",
    "result=[]\n",
    "hyperparameter_combinations = list(itertools.product(t2.columns, t2.columns))\n",
    "for i,j in hyperparameter_combinations:\n",
    "    if(i==j):\n",
    "        continue\n",
    "    group1, group2 = t2[i],t2[j]\n",
    "    # 执行卡方独立性检验\n",
    "    contingency_table  = pd.crosstab(t2[i],t2[j])\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    corr_coefficient, p_value1 = stats.pearsonr(group1, group2)\n",
    "    result .append([i,j,  p,p_value1 ])\n",
    "result = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53b5f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,4):\n",
    "    print(result[result[i]<.01].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f593d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.000000e+01\n",
       "mean     3.967852e-01\n",
       "std      3.223808e-01\n",
       "min      8.727921e-17\n",
       "25%      5.928997e-02\n",
       "50%      3.663566e-01\n",
       "75%      6.906527e-01\n",
       "max      9.826200e-01\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[3].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189000d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ae5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##特征太多了 （）\n",
    "\n",
    "# 1. 没有信息的值： 删除方差为0的(没有),使用低方差滤波器处理\n",
    "\n",
    "# - person相关系数、speraman、kendall 来说明\n",
    "\n",
    "# 2. 直接指标：\n",
    "# -个人\n",
    "# -疾病史\n",
    "# -发病\n",
    "# -治疗\n",
    "\n",
    "# 方法：\n",
    "# - 距离相关系数\n",
    "# - 灰度关联\n",
    "\n",
    "# 3. 带target的\n",
    "# - 带LASSO 回归判断\n",
    "# - svm递归特征消除\n",
    "\n",
    "# ？ 降到多少维度\n",
    "\n",
    "# 4. 检验\n",
    "# - 独立性检验\n",
    "# - 信息熵理论验证\n",
    "# - 人类知识:专家知识\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bda59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5895fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
